{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32a971f5",
   "metadata": {
    "id": "32a971f5"
   },
   "source": [
    "# EfficientDet Training On A Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75322120",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5030,
     "status": "ok",
     "timestamp": 1747647737060,
     "user": {
      "displayName": "Jaehyung Park (재형)",
      "userId": "02611152586097866845"
     },
     "user_tz": -540
    },
    "id": "75322120",
    "outputId": "98243665-6942-4144-b907-03390923626e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pycocotools in /usr/local/lib/python3.11/dist-packages (2.0.8)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
      "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
      "Collecting tensorboardX\n",
      "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (6.0.2)\n",
      "Requirement already satisfied: webcolors in /usr/local/lib/python3.11/dist-packages (24.11.1)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.4.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.71.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.8)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboard) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (5.29.4)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (75.2.0)\n",
      "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.17.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.1.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard) (3.0.2)\n",
      "Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tensorboardX\n",
      "Successfully installed tensorboardX-2.6.2.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pycocotools numpy opencv-python tqdm tensorboard tensorboardX pyyaml webcolors matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ef870f",
   "metadata": {
    "id": "81ef870f"
   },
   "source": [
    "### 1. Prepare Custom Dataset/Pretrained Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "mxmWv39AfCMd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20378,
     "status": "ok",
     "timestamp": 1747647758319,
     "user": {
      "displayName": "Jaehyung Park (재형)",
      "userId": "02611152586097866845"
     },
     "user_tz": -540
    },
    "id": "mxmWv39AfCMd",
    "outputId": "266ee411-b69e-475e-c1f3-5f1961d3160e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "l9dtgU5jfIZz",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 501,
     "status": "ok",
     "timestamp": 1747647760401,
     "user": {
      "displayName": "Jaehyung Park (재형)",
      "userId": "02611152586097866845"
     },
     "user_tz": -540
    },
    "id": "l9dtgU5jfIZz",
    "outputId": "d4fa2750-bbce-4d0d-953b-438aee1ccd41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 작업 디렉토리: /content\n",
      "디렉토리 이동 완료: /content/drive/MyDrive/2025Spring-DL/Yet-Another-EfficientDet-Pytorch\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "# 현재 디렉토리 확인\n",
    "print(\"현재 작업 디렉토리:\", os.getcwd())\n",
    "\n",
    "# 이동할 디렉토리 지정 (구글 드라이브 경로 내)\n",
    "target_dir = \"/content/drive/MyDrive/2025Spring-DL/Yet-Another-EfficientDet-Pytorch\"\n",
    "\n",
    "# 존재 여부 확인 후 이동\n",
    "if os.path.exists(target_dir):\n",
    "    os.chdir(target_dir)\n",
    "    sys.path.append(target_dir)\n",
    "    print(\"디렉토리 이동 완료:\", os.getcwd())\n",
    "else:\n",
    "    print(\"디렉토리가 존재하지 않습니다:\", target_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ab0bd46",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1002,
     "status": "ok",
     "timestamp": 1747647763019,
     "user": {
      "displayName": "Jaehyung Park (재형)",
      "userId": "02611152586097866845"
     },
     "user_tz": -540
    },
    "id": "6ab0bd46",
    "outputId": "c9bdfc5d-df50-453c-fb05-72615d508bab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# datasets 디렉토리 내 폴더 목록:\n",
      "  - household\n",
      "\n",
      "# weights 디렉토리 내 파일 목록:\n",
      "  - efficientdet-d0.pth\n",
      "\n",
      "# household.yml 파일 내용:\n",
      "project_name: household  # also the folder name of the dataset that under data_path folder\n",
      "train_set: train\n",
      "val_set: val\n",
      "num_gpus: 1\n",
      "\n",
      "# mean and std in RGB order, actually this part should remain unchanged as long as your dataset is similar to coco.\n",
      "mean: [ 0.485, 0.456, 0.406 ]\n",
      "std: [ 0.229, 0.224, 0.225 ]\n",
      "\n",
      "# this anchor is adapted to the dataset\n",
      "anchors_scales: '[2 ** 0, 2 ** (1.0 / 3.0), 2 ** (2.0 / 3.0)]'\n",
      "anchors_ratios: '[(0.7, 1.4), (1.0, 1.0), (1.5, 0.7)]'\n",
      "\n",
      "obj_list: [\n",
      "    'HousePlant', 'Bed', 'CellPhone', 'Pan', 'SideTable', 'Pencil', 'TissueBox', 'Book', 'Drawer',\n",
      "    'Television', 'BaseballBat', 'Painting', 'GarbageBag', 'DiningTable', 'AlarmClock', 'Cabinet',\n",
      "    'Shelf', 'Lettuce', 'Desk', 'SprayBottle', 'Sofa', 'Pen', 'GarbageCan', 'Chair', 'ArmChair',\n",
      "    'BasketBall', 'Box', 'Toilet', 'Watch', 'TennisRacket', 'Sink', 'Laptop', 'RemoteControl',\n",
      "    'Dresser', 'Statue', 'Candle', 'TVStand', 'Stool', 'Pillow', 'DeskLamp', 'SinkBasin', 'Fridge',\n",
      "    'Cart', 'Egg', 'DishSponge', 'SaltShaker', 'Plunger', 'CreditCard', 'Mug', 'CounterTop',\n",
      "    'SoapBottle', 'Spatula', 'TeddyBear', 'PaperTowelRoll', 'PepperShaker', 'Bottle', 'Vase',\n",
      "    'Plate', 'Pot', 'Fork', 'Tomato', 'Faucet', 'FloorLamp', 'Apple', 'Knife', 'Newspaper',\n",
      "    'LaundryHamper', 'Ladle', 'Kettle', 'KeyChain', 'ToiletPaper', 'Bowl', 'DogBed', 'ClothesDryer',\n",
      "    'Potato', 'Safe', 'Microwave', 'ButterKnife', 'Bread', 'Toaster', 'CoffeeMachine', 'RoomDecor',\n",
      "    'CoffeeTable', 'WineBottle', 'Cup', 'VacuumCleaner', 'Cloth', 'Ottoman', 'Spoon', 'SoapBar',\n",
      "    'Boots', 'TableTopDecor', 'Dumbbell'\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "current_dir = target_dir\n",
    "\n",
    "# ------------------------------\n",
    "# prepare dataset (하위 폴더만)\n",
    "# ------------------------------\n",
    "datasets_dir = os.path.join(current_dir, \"datasets\")\n",
    "\n",
    "if os.path.exists(datasets_dir) and os.path.isdir(datasets_dir):\n",
    "    folders = [item for item in os.listdir(datasets_dir)\n",
    "               if os.path.isdir(os.path.join(datasets_dir, item))]\n",
    "    print(f\"\\n# datasets 디렉토리 내 폴더 목록:\")\n",
    "    for folder in folders:\n",
    "        print(\"  -\", folder)\n",
    "else:\n",
    "    print(f\"# Fail\")\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# prepare pretrained weights (하위 파일만)\n",
    "# ------------------------------\n",
    "weights_dir = os.path.join(current_dir, \"weights\")\n",
    "\n",
    "if os.path.exists(weights_dir) and os.path.isdir(weights_dir):\n",
    "    files = [item for item in os.listdir(weights_dir)\n",
    "             if os.path.isfile(os.path.join(weights_dir, item))]\n",
    "    print(f\"\\n# weights 디렉토리 내 파일 목록:\")\n",
    "    for file in files:\n",
    "        print(\"  -\", file)\n",
    "else:\n",
    "    print(f\"# Fail\")\n",
    "\n",
    "\n",
    "# prepare project file projects/household.yml\n",
    "# showing its contents here\n",
    "print(\"\\n# household.yml 파일 내용:\")\n",
    "! cat projects/household.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c79ec6d",
   "metadata": {
    "id": "3c79ec6d"
   },
   "source": [
    "### 2. Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZhlUGD4cgHPl",
   "metadata": {
    "id": "ZhlUGD4cgHPl"
   },
   "source": [
    "훈련을 위한 명령어들.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xwv3Mkb0iu05",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 91165,
     "status": "ok",
     "timestamp": 1747647860724,
     "user": {
      "displayName": "Jaehyung Park (재형)",
      "userId": "02611152586097866845"
     },
     "user_tz": -540
    },
    "id": "xwv3Mkb0iu05",
    "outputId": "026b925d-d42a-4d88-8efa-a07b2294a9ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=1.14s)\n",
      "creating index...\n",
      "index created!\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "loading annotations into memory...\n",
      "Done (t=0.57s)\n",
      "creating index...\n",
      "index created!\n",
      "[Warning] Ignoring Error(s) in loading state_dict for EfficientDetBackbone:\n",
      "\tsize mismatch for classifier.header.pointwise_conv.conv.weight: copying a param with shape torch.Size([810, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([837, 64, 1, 1]).\n",
      "\tsize mismatch for classifier.header.pointwise_conv.conv.bias: copying a param with shape torch.Size([810]) from checkpoint, the shape in current model is torch.Size([837]).\n",
      "[Warning] Don't panic if you see this, this might be because you load a pretrained weights with different number of classes. The rest of the weights should be loaded already.\n",
      "[Info] loaded weights: efficientdet-d0.pth, resuming checkpoint from step: 0\n",
      "[Info] freezed backbone\n",
      "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "Step: 12. Epoch: 0/10. Iteration: 13/347. Cls loss: 211004.03125. Reg loss: 2.87665. Total loss: 211006.90625:   4% 13/347 [01:08<08:52,  1.60s/it]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7e21f8474fe0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1582, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 149, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.11/multiprocessing/popen_fork.py\", line 40, in wait\n",
      "    if not wait([self.sentinel], timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.11/multiprocessing/connection.py\", line 948, in wait\n",
      "    ready = selector.select(timeout)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.11/selectors.py\", line 415, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt: \n",
      "Step: 12. Epoch: 0/10. Iteration: 13/347. Cls loss: 211004.03125. Reg loss: 2.87665. Total loss: 211006.90625:   4% 13/347 [01:09<29:45,  5.35s/it]\n"
     ]
    }
   ],
   "source": [
    "# with a coco-pretrained, you can freeze the backbone and train heads only\n",
    "# to speed up training and help convergence.\n",
    "\n",
    "! python train.py -c 0 -p household \\\n",
    "    --batch_size 32 --lr 1e-3 --num_epochs 10 \\\n",
    "    --load_weights ./weights/efficientdet-d0.pth \\\n",
    "    --head_only False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1338ee",
   "metadata": {
    "id": "de1338ee"
   },
   "outputs": [],
   "source": [
    "# 이어서 학습하기: --load_weights last\n",
    "\n",
    "! python train.py -c 0 -p household \\\n",
    "    --lr 1e-3 --batch_size 16 \\\n",
    "    --load_weights last \\\n",
    "    --num_epochs 16 --save_interval 100 \\\n",
    "    --head_only True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56acd0c",
   "metadata": {
    "id": "d56acd0c"
   },
   "source": [
    "### 3. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feeaff31",
   "metadata": {
    "id": "feeaff31"
   },
   "outputs": [],
   "source": [
    "# get latest weight file\n",
    "%cd logs/household\n",
    "weight_file = !ls -Art | grep efficientdet\n",
    "%cd ../..\n",
    "\n",
    "# uncomment the next line to specify a weight file\n",
    "#weight_file[-1] = 'efficientdet-d0_49_1400.pth'\n",
    "\n",
    "! python coco_eval.py -c 0 -p household \\\n",
    "    -w \"logs/household/{weight_file[-1]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48b7ce1",
   "metadata": {
    "id": "e48b7ce1"
   },
   "outputs": [],
   "source": [
    "# Or just:\n",
    "! python coco_eval.py -c 0 -p household \\\n",
    "    -w #./path/to/your/weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aaa3ca1",
   "metadata": {
    "id": "3aaa3ca1"
   },
   "source": [
    "### 4. Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9d0648",
   "metadata": {
    "id": "cc9d0648"
   },
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from torch.backends import cudnn\n",
    "\n",
    "from backbone import EfficientDetBackbone\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from efficientdet.utils import BBoxTransform, ClipBoxes\n",
    "from utils.utils import preprocess, invert_affine, postprocess\n",
    "\n",
    "\n",
    "compound_coef = 0\n",
    "force_input_size = None  # set None to use default size\n",
    "img_path = 'datasets/household/val/4_teleport_42.jpg'\n",
    "\n",
    "threshold = 0.2\n",
    "iou_threshold = 0.2\n",
    "\n",
    "use_cuda = True\n",
    "use_float16 = False\n",
    "cudnn.fastest = True\n",
    "cudnn.benchmark = True\n",
    "\n",
    "obj_list = [\n",
    "    'HousePlant', 'Bed', 'CellPhone', 'Pan', 'SideTable', 'Pencil', 'TissueBox', 'Book', 'Drawer',\n",
    "    'Television', 'BaseballBat', 'Painting', 'GarbageBag', 'DiningTable', 'AlarmClock', 'Cabinet',\n",
    "    'Shelf', 'Lettuce', 'Desk', 'SprayBottle', 'Sofa', 'Pen', 'GarbageCan', 'Chair', 'ArmChair',\n",
    "    'BasketBall', 'Box', 'Toilet', 'Watch', 'TennisRacket', 'Sink', 'Laptop', 'RemoteControl',\n",
    "    'Dresser', 'Statue', 'Candle', 'TVStand', 'Stool', 'Pillow', 'DeskLamp', 'SinkBasin', 'Fridge',\n",
    "    'Cart', 'Egg', 'DishSponge', 'SaltShaker', 'Plunger', 'CreditCard', 'Mug', 'CounterTop',\n",
    "    'SoapBottle', 'Spatula', 'TeddyBear', 'PaperTowelRoll', 'PepperShaker', 'Bottle', 'Vase',\n",
    "    'Plate', 'Pot', 'Fork', 'Tomato', 'Faucet', 'FloorLamp', 'Apple', 'Knife', 'Newspaper',\n",
    "    'LaundryHamper', 'Ladle', 'Kettle', 'KeyChain', 'ToiletPaper', 'Bowl', 'DogBed', 'ClothesDryer',\n",
    "    'Potato', 'Safe', 'Microwave', 'ButterKnife', 'Bread', 'Toaster', 'CoffeeMachine', 'RoomDecor',\n",
    "    'CoffeeTable', 'WineBottle', 'Cup', 'VacuumCleaner', 'Cloth', 'Ottoman', 'Spoon', 'SoapBar',\n",
    "    'Boots', 'TableTopDecor', 'Dumbbell'\n",
    "]\n",
    "\n",
    "\n",
    "# tf bilinear interpolation is different from any other's, just make do\n",
    "input_sizes = [512, 640, 768, 896, 1024, 1280, 1280, 1536]\n",
    "input_size = input_sizes[compound_coef] if force_input_size is None else force_input_size\n",
    "ori_imgs, framed_imgs, framed_metas = preprocess(img_path, max_size=input_size)\n",
    "\n",
    "if use_cuda:\n",
    "    x = torch.stack([torch.from_numpy(fi).cuda() for fi in framed_imgs], 0)\n",
    "else:\n",
    "    x = torch.stack([torch.from_numpy(fi) for fi in framed_imgs], 0)\n",
    "\n",
    "x = x.to(torch.float32 if not use_float16 else torch.float16).permute(0, 3, 1, 2)\n",
    "\n",
    "model = EfficientDetBackbone(compound_coef=compound_coef, num_classes=len(obj_list),\n",
    "\n",
    "                             # replace this part with your project's anchor config\n",
    "                             ratios=[(0.7, 1.4), (1.0, 1.0), (1.5, 0.7)],\n",
    "                             scales=[2 ** 0, 2 ** (1.0 / 3.0), 2 ** (2.0 / 3.0)])\n",
    "\n",
    "# Need to modify the weight file\n",
    "model.load_state_dict(torch.load('logs/household/'+weight_file[-1]))\n",
    "model.requires_grad_(False)\n",
    "model.eval()\n",
    "\n",
    "if use_cuda:\n",
    "    model = model.cuda()\n",
    "if use_float16:\n",
    "    model = model.half()\n",
    "\n",
    "with torch.no_grad():\n",
    "    features, regression, classification, anchors = model(x)\n",
    "\n",
    "    regressBoxes = BBoxTransform()\n",
    "    clipBoxes = ClipBoxes()\n",
    "\n",
    "    out = postprocess(x,\n",
    "                      anchors, regression, classification,\n",
    "                      regressBoxes, clipBoxes,\n",
    "                      threshold, iou_threshold)\n",
    "\n",
    "out = invert_affine(framed_metas, out)\n",
    "\n",
    "for i in range(len(ori_imgs)):\n",
    "    if len(out[i]['rois']) == 0:\n",
    "        continue\n",
    "    ori_imgs[i] = ori_imgs[i].copy()\n",
    "    for j in range(len(out[i]['rois'])):\n",
    "        (x1, y1, x2, y2) = out[i]['rois'][j].astype(np.int)\n",
    "        cv2.rectangle(ori_imgs[i], (x1, y1), (x2, y2), (255, 255, 0), 2)\n",
    "        obj = obj_list[out[i]['class_ids'][j]]\n",
    "        score = float(out[i]['scores'][j])\n",
    "\n",
    "        cv2.putText(ori_imgs[i], '{}, {:.3f}'.format(obj, score),\n",
    "                    (x1, y1 + 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n",
    "                    (255, 255, 0), 1)\n",
    "\n",
    "        plt.imshow(ori_imgs[i])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
